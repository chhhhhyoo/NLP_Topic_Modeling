{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average Training Loss: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▎        | 1/8 [01:26<10:05, 86.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.05\n",
      "Epoch 2: Average Training Loss: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 2/8 [02:53<08:39, 86.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.05\n",
      "Epoch 3: Average Training Loss: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 3/8 [04:20<07:15, 87.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.06\n",
      "Epoch 4: Average Training Loss: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 4/8 [05:58<06:05, 91.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.06\n",
      "Epoch 5: Average Training Loss: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▎   | 5/8 [07:28<04:31, 90.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.06\n",
      "Epoch 6: Average Training Loss: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 6/8 [08:54<02:58, 89.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.06\n",
      "Epoch 7: Average Training Loss: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|████████▊ | 7/8 [10:21<01:28, 88.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.06\n",
      "Epoch 8: Average Training Loss: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 8/8 [11:48<00:00, 88.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForTokenClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the dataset\n",
    "# dataset = load_dataset(\"midas/duc2001\", \"raw\")[\"test\"]\n",
    "# dataset = load_dataset(\"midas/inspec\", \"raw\")[\"test\"]\n",
    "dataset = load_dataset(\"midas/nus\", \"raw\")[\"test\"]\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Constants\n",
    "MAX_LEN = 75\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Prepare mapping for labels\n",
    "tag2idx = {'B': 0, 'I': 1, 'O': 2}\n",
    "\n",
    "# Adjust these weights based on your specific dataset and class imbalance\n",
    "class_weights = torch.tensor([10.0, 15.0, 0.1])  # Example weights for 'B', 'I', 'O'\n",
    "# class_weights = torch.tensor([10.0, 15.0, 0.1]).cuda()  # Example weights for 'B', 'I', 'O' if GPU applicable\n",
    "\n",
    "# Tokenization and encoding for BERT\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "\n",
    "for i, item in enumerate(dataset):\n",
    "    # Join tokens into a single string\n",
    "    text = ' '.join([t.lower() for t in item['document']])\n",
    "    tags = item['doc_bio_tags']\n",
    "\n",
    "    # Encode text\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Prepare labels\n",
    "    tag_ids = [tag2idx[tag] for tag in tags] + [tag2idx['O']] * (MAX_LEN - len(tags))\n",
    "    tag_ids = tag_ids[:MAX_LEN]  # Ensure label length matches input length\n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "    labels.append(torch.tensor(tag_ids))\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_ids = torch.stack(input_ids)\n",
    "attention_masks = torch.stack(attention_masks)\n",
    "labels = torch.stack(labels)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_inputs, val_inputs, train_labels, val_labels, train_masks, val_masks = train_test_split(\n",
    "    input_ids, labels, attention_masks, test_size=0.1, random_state=2018\n",
    ")\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Load BERT for token classification\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(tag2idx),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "# Set up the optimizer\n",
    "# optimizer = AdamW(model.parameters(), lr=3e-5, eps=1e-8)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, eps=1e-8)  # increased learning rate\n",
    "\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 4)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to calculate the accuracy of predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# We have a class imbalance which is hindering our model performance\n",
    "# Apply focal loss to focus more on hard-to-classify examples by down-weighting the loss contributed by well-classified examples(easy-classify)\n",
    "def hybrid_loss(logits, labels, weights, alpha=0.8, gamma=2.0):\n",
    "    # Softmax and cross entropy loss\n",
    "    ce_loss = torch.nn.functional.cross_entropy(logits, labels, reduction='none', weight=weights)\n",
    "    \n",
    "    # Calculate probabilities of the true class\n",
    "    p_t = torch.exp(-ce_loss)\n",
    "    \n",
    "    # Calculate focal component\n",
    "    focal_loss = (alpha * (1 - p_t) ** gamma * ce_loss).mean()\n",
    "    \n",
    "    return focal_loss\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(8), desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = hybrid_loss(outputs.logits.view(-1, 3), b_labels.view(-1), class_weights)\n",
    "\n",
    "        # # Apply class weights\n",
    "        # log_probs = torch.nn.functional.log_softmax(outputs.logits, dim=-1)\n",
    "        # weighted_loss = torch.nn.functional.nll_loss(log_probs.view(-1, model.num_labels), b_labels.view(-1), weight=class_weights)\n",
    "\n",
    "        # weighted_loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # total_loss += weighted_loss.item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Average Training Loss: {total_loss / len(train_dataloader):.2f}')\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy, nb_eval_steps = 0, 0, 0\n",
    "    \n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    print(f'Validation Accuracy: {eval_accuracy / nb_eval_steps:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.055757575757575756\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and the tokenizer\n",
    "model.save_pretrained('./model_save_v4/')\n",
    "tokenizer.save_pretrained('./model_save_v4/')\n",
    "\n",
    "# Load the model and the tokenizer\n",
    "model = BertForTokenClassification.from_pretrained('./model_save_v4/')\n",
    "tokenizer = BertTokenizer.from_pretrained('./model_save_v4/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywordextract(text, model, tokenizer, device):\n",
    "    # Tokenize input\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text,                      # Document to encode.\n",
    "        add_special_tokens=True,   # Add '[CLS]' and '[SEP]'\n",
    "        max_length=64,             # Pad or truncate.\n",
    "        padding='max_length',      # Pad to max_length.\n",
    "        truncation=True,           # Truncate to max_length.\n",
    "        return_attention_mask=True,# Construct attention masks.\n",
    "        return_tensors='pt',       # Return PyTorch tensors.\n",
    "    )\n",
    "    \n",
    "    # Move tensors to the correct device\n",
    "    input_ids = encoded_dict['input_ids'].to(device)\n",
    "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
    "\n",
    "    # Model inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Decode predictions\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    predictions = predictions[0].tolist()  # Remove the batch dimension and convert to list\n",
    "\n",
    "    # Convert input_ids to tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "    # print(\"Tokens and Predictions:\")  # Debugging output\n",
    "    # for token, prediction in zip(tokens, predictions):\n",
    "    #     print(f\"{token}: {prediction}\")\n",
    "\n",
    "    # Extract keywords based on the 'B' and 'I' predictions\n",
    "    keywords = []\n",
    "    current_keyword = []\n",
    "    for token, pred in zip(tokens, predictions):\n",
    "        if pred == 1:  # Corresponds to 'B'\n",
    "            if current_keyword:  # Save the previous keyword if it exists\n",
    "                keywords.append(\"\".join(current_keyword).replace(\"##\", \"\"))\n",
    "            current_keyword = [token]  # Start a new keyword\n",
    "        elif pred == 2 and current_keyword:  # Corresponds to 'I'\n",
    "            current_keyword.append(token)\n",
    "        else:\n",
    "            if current_keyword:\n",
    "                keywords.append(\"\".join(current_keyword).replace(\"##\", \"\"))\n",
    "                current_keyword = []\n",
    "    \n",
    "    # Check if the last token was part of a keyword\n",
    "    if current_keyword:\n",
    "        keywords.append(\"\".join(current_keyword).replace(\"##\", \"\"))\n",
    "\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords: ['machine', 'learning', 'ml', 'artificial', 'intelligence', 'statistical', 'algorithms', 'learn', 'data', 'explicit', 'instructions']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Machine learning (ML) is a field of study in artificial intelligence \n",
    "concerned with the development and study of statistical algorithms that \n",
    "can learn from data and generalize to unseen data, and thus \n",
    "perform tasks without explicit instructions.\"\"\"\n",
    "keywords = keywordextract(text, model, tokenizer, device)\n",
    "print(\"Extracted Keywords:\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords: ['machine', 'learning', '(', 'ml', ')', 'field', 'in', 'artificial', 'intelligence', 'with', 'development', 'study', 'of', 'statistical', 'algorithms', 'data', 'and', 'ize', 'to', 'data', ',', 'and', 'thus', 'perform', 'tasks', 'without', 'instructions', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Machine learning (ML) is a field of study in artificial intelligence \n",
    "concerned with the development and study of statistical algorithms that \n",
    "can learn from data and generalize to unseen data, and thus \n",
    "perform tasks without explicit instructions.\"\"\"\n",
    "keywords = keywordextract(text, model, tokenizer, device)\n",
    "print(\"Extracted Keywords:\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords: ['machine', 'learning', 'ml', 'artificial', 'intelligence', 'statistical', 'algorithms', 'learn', 'data', 'explicit', 'instructions']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Machine learning (ML) is a field of study in artificial intelligence \n",
    "concerned with the development and study of statistical algorithms that \n",
    "can learn from data and generalize to unseen data, and thus \n",
    "perform tasks without explicit instructions.\"\"\"\n",
    "keywords = keywordextract(text, model, tokenizer, device)\n",
    "print(\"Extracted Keywords:\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different dataset.\n",
    "optimizing loss function -> according to diff feature\n",
    "                            \n",
    "\n",
    "augmenting the weight to each class\n",
    "\n",
    "add dropout layer => 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dcg_at_k(relevance_scores, k, method=1):\n",
    "    \"\"\"Calculate discounted cumulative gain (DCG) at rank k.\n",
    "\n",
    "    Args:\n",
    "        relevance_scores (list of float): The list of relevance scores.\n",
    "        k (int): The number of results to consider.\n",
    "        method (int): The method to compute DCG, 0 or 1.\n",
    "\n",
    "    Returns:\n",
    "        float: The DCG score.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the method is not 0 or 1.\n",
    "    \"\"\"\n",
    "    relevance_scores = np.asfarray(relevance_scores)[:k]\n",
    "    if relevance_scores.size:\n",
    "        if method == 0:\n",
    "            return relevance_scores[0] + np.sum(relevance_scores[1:] / np.log2(np.arange(2, relevance_scores.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(relevance_scores / np.log2(np.arange(2, relevance_scores.size + 2)))\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(relevance_scores, k, method=1):\n",
    "    \"\"\"Calculate normalized discounted cumulative gain (NDCG) at rank k.\n",
    "\n",
    "    Args:\n",
    "        relevance_scores (list of float): The list of relevance scores.\n",
    "        k (int): The number of results to consider.\n",
    "        method (int): The method to compute DCG, 0 or 1.\n",
    "\n",
    "    Returns:\n",
    "        float: The NDCG score.\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(relevance_scores, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.0\n",
    "    return dcg_at_k(relevance_scores, k, method) / dcg_max\n",
    "\n",
    "def mean_reciprocal_rank(ranking_lists):\n",
    "    \"\"\"Calculate the mean reciprocal rank (MRR).\n",
    "\n",
    "    Args:\n",
    "        ranking_lists (list of list of int): Each inner list is a set of binary values (0 or 1)\n",
    "            indicating the absence or presence of relevant items.\n",
    "\n",
    "    Returns:\n",
    "        float: The MRR score.\n",
    "    \"\"\"\n",
    "    first_relevant = (np.asarray(rankings).nonzero()[0] for rankings in ranking_lists)\n",
    "    return np.mean([1.0 / (ranking[0] + 1) if ranking.size else 0 for ranking in first_relevant])\n",
    "\n",
    "def calculate_relevance_scores(true_keywords, predicted_keywords):\n",
    "    \"\"\"Calculates relevance scores where 1 indicates relevance and 0 indicates irrelevance.\n",
    "   \n",
    "    Args:\n",
    "        true_keywords (list of str): The list of true keywords.\n",
    "        predicted_keywords (list of tuples): List of predicted keywords with their scores.\n",
    "   \n",
    "    Returns:\n",
    "        list of int: Relevance scores (1 or 0) for each predicted keyword.\n",
    "    \"\"\"\n",
    "    return [1 if keyword in true_keywords else 0 for keyword, _ in predicted_keywords]\n",
    "\n",
    "def evaluate_keyword_extraction(true_data, predictions):\n",
    "    \"\"\"Evaluates the keyword extraction algorithm using NDCG and MRR scoring metrics.\n",
    "   \n",
    "    Args:\n",
    "        true_data (list of list of str): List of lists containing true keywords for each document.\n",
    "        predictions (list of list of tuples): List of lists, each containing tuples of keywords and their confidence scores.\n",
    "   \n",
    "    Returns:\n",
    "        tuple of (float, float): Mean NDCG score and Mean MRR score.\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    mrr_scores = []\n",
    "\n",
    "    for true_keywords, predicted_keywords_with_scores in zip(true_data, predictions):\n",
    "        predicted_keywords_with_scores.sort(key=lambda x: x[1], reverse=True)  # Sort by confidence score descending\n",
    "        predicted_keywords = [kw for kw, _ in predicted_keywords_with_scores]\n",
    "        relevance_scores = calculate_relevance_scores(true_keywords, predicted_keywords_with_scores)\n",
    "\n",
    "        # Compute NDCG\n",
    "        ndcg_score = ndcg_at_k(relevance_scores, k=len(relevance_scores))\n",
    "        ndcg_scores.append(ndcg_score)\n",
    "       \n",
    "        # Compute MRR\n",
    "        rs = [[1 if keyword in true_keywords else 0 for keyword in predicted_keywords]]\n",
    "        mrr_score = mean_reciprocal_rank(rs)\n",
    "        mrr_scores.append(mrr_score)\n",
    "   \n",
    "    mean_ndcg = np.mean(ndcg_scores)\n",
    "    mean_mrr = np.mean(mrr_scores)\n",
    "    return mean_ndcg, mean_mrr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywordextract(text, model, tokenizer, device):\n",
    "    # Tokenize input\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text,                      # Document to encode.\n",
    "        add_special_tokens=True,   # Add '[CLS]' and '[SEP]'\n",
    "        max_length=64,             # Pad or truncate.\n",
    "        padding='max_length',      # Pad to max_length.\n",
    "        truncation=True,           # Truncate to max_length.\n",
    "        return_attention_mask=True,# Construct attention masks.\n",
    "        return_tensors='pt',       # Return PyTorch tensors.\n",
    "    )\n",
    "    input_ids = encoded_dict['input_ids'].to(device)\n",
    "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
    "\n",
    "    # Model inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    predictions = predictions[0].tolist()  # Remove the batch dimension\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "    # Extract keywords based on predictions\n",
    "    keywords = []\n",
    "    current_keyword = []\n",
    "    keyword_scores = []\n",
    "    for token, pred in zip(tokens, predictions):\n",
    "        # Remove the BERT's subword prefix if applicable\n",
    "        if token.startswith(\"##\"):\n",
    "            token = token[2:]\n",
    "        else:\n",
    "            # Append and reset the current keyword when encountering a new starting token without '##'\n",
    "            if current_keyword:\n",
    "                keywords.append(\"\".join(current_keyword).replace(\"##\", \"\"))\n",
    "                keyword_scores.append(max(keyword_scores))\n",
    "                current_keyword = []\n",
    "                keyword_scores = []\n",
    "\n",
    "        # Calculate confidence\n",
    "        confidence = torch.softmax(logits, dim=-1)[0, :, pred].max().item()\n",
    "\n",
    "        if pred == 1:  # 'B' for beginning of keyword\n",
    "            if current_keyword:\n",
    "                keywords.append(\"\".join(current_keyword).replace(\"##\", \"\"))\n",
    "                keyword_scores.append(max(keyword_scores))\n",
    "            current_keyword = [token]\n",
    "            keyword_scores = [confidence]\n",
    "        elif pred == 2 and current_keyword:  # 'I' for continuation\n",
    "            current_keyword.append(token)\n",
    "            keyword_scores.append(confidence)\n",
    "        else:\n",
    "            if current_keyword:\n",
    "                keywords.append(\"\".join(current_keyword).replace(\"##\", \"\"))\n",
    "                keyword_scores.append(max(keyword_scores))\n",
    "                current_keyword = []\n",
    "                keyword_scores = []\n",
    "\n",
    "    if current_keyword:\n",
    "        keywords.append(\"\".join(current_keyword).replace(\"##\", \"\"))\n",
    "        keyword_scores.append(max(keyword_scores))\n",
    "\n",
    "    return list(zip(keywords, keyword_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG: 0.000\n",
      "Mean MRR: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for evaluation\n",
    "true_keywords_list = [['machine', 'learning', 'ml', 'artificial', 'intelligence', 'statistical', 'algorithms', 'learn', 'data', 'explicit', 'instructions']]  # Note the double brackets\n",
    "\n",
    "text = \"\"\"Machine learning (ML) is a field of study in artificial intelligence \n",
    "concerned with the development and study of statistical algorithms that \n",
    "can learn from data and generalize to unseen data, and thus \n",
    "perform tasks without explicit instructions.\"\"\"\n",
    "\n",
    "predicted_keywords_with_scores = keywordextract(text, model, tokenizer, device)\n",
    "predicted_keywords_with_scores_list = [predicted_keywords_with_scores]  # Note the double brackets\n",
    "\n",
    "# Evaluation\n",
    "mean_ndcg, mean_mrr = evaluate_keyword_extraction(true_keywords_list, predicted_keywords_with_scores_list)\n",
    "print(f\"Mean NDCG: {mean_ndcg:.3f}\")\n",
    "print(f\"Mean MRR: {mean_mrr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_keywords_with_scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m keywords_only \u001b[38;5;241m=\u001b[39m [keyword \u001b[38;5;28;01mfor\u001b[39;00m keyword, _ \u001b[38;5;129;01min\u001b[39;00m predicted_keywords_with_scores_list]\n\u001b[0;32m      2\u001b[0m keywords_only\n",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m keywords_only \u001b[38;5;241m=\u001b[39m [keyword \u001b[38;5;28;01mfor\u001b[39;00m keyword, _ \u001b[38;5;129;01min\u001b[39;00m predicted_keywords_with_scores_list]\n\u001b[0;32m      2\u001b[0m keywords_only\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "keywords_only = [keyword for keyword, _ in predicted_keywords_with_scores_list]\n",
    "keywords_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
